{
  "openapi": "3.0.0",
  "info": {
    "title": "Audio Mode Analysis API",
    "version": "1.0.0",
    "description": "API for analyzing audio segments and inferring musical modes."
  },
  "servers": [
    {
      "url": "https://music-theory-toolkit-backend-780189092579.us-central1.run.app",
      "description": "Production server (Google Cloud Run)"
    },
    {
      "url": "http://localhost:8080",
      "description": "Local development server"
    }
  ],
  "paths": {
    "/analyze-mode/": {
      "post": {
        "summary": "Analyze musical mode of an audio segment",
        "requestBody": {
          "required": true,
          "content": {
            "multipart/form-data": {
              "schema": {
                "type": "object",
                "properties": {
                  "audio": {
                    "type": "string",
                    "format": "binary",
                    "description": "The audio file to analyze (e.g., WAV, MP3)",
                    "example": "audio.wav"
                  },
                  "start": {
                    "type": "number",
                    "format": "float",
                    "description": "Start time in seconds for the segment to analyze. Defaults to 0.0.",
                    "example": 0.0
                  },
                  "end": {
                    "type": "number",
                    "format": "float",
                    "description": "End time in seconds for the segment to analyze. If not provided, analysis goes to the end of the audio.",
                    "example": 10.0
                  }
                },
                "required": ["audio"]
              },
              "encoding": {
                "audio": {
                  "contentType": "audio/wav, audio/mpeg"
                }
              }
            }
          }
        },
        "responses": {
          "200": {
            "description": "Mode analysis results",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ModeAnalysisResponse"
                },
                "example": {
                  "duration_seconds": 60.5,
                  "segment_seconds": 10.0,
                  "sample_rate": 22050,
                  "average_chroma": [0.8, 0.1, 0.7, 0.1, 0.9, 0.2, 0.6, 0.1, 0.5, 0.1, 0.4, 0.1],
                  "chromagram_frames": [
                    [0.7, 0.0, 0.6, 0.0, 0.8, 0.0, 0.5, 0.0, 0.4, 0.0, 0.3, 0.0],
                    [0.8, 0.1, 0.7, 0.1, 0.9, 0.1, 0.6, 0.1, 0.5, 0.1, 0.4, 0.1]
                  ],
                  "frame_count_per_pitch_class": {
                    "C": 120,
                    "C#": 10,
                    "D": 100,
                    "D#": 5,
                    "E": 150,
                    "F": 15,
                    "F#": 90,
                    "G": 20,
                    "G#": 80,
                    "A": 25,
                    "A#": 70,
                    "B": 30
                  },
                  "detected_notes": ["C", "D", "E", "F#", "G#", "A#"],
                  "suggested_mode": "C Major",
                  "local_key": "C",
                  "match_scores": {
                    "C Major": 0.98,
                    "G Major": 0.75,
                    "A Minor": 0.82
                  },
                  "visuals": {
                    "chromagram_base64": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAQAAAC1HAwCAAAAC0lEQVR42mNkYAAAAAYAAjCB0C8AAAAASUVORK5CYII=",
                    "histogram_base64": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAQAAAC1HAwCAAAAC0lEQVR42mNkYAAAAAYAAjCB0C8AAAAASUVORK5CYII="
                  }
                }
              }
            }
          },
          "400": {
            "description": "Bad Request - Invalid audio file or parameters"
          },
          "500": {
            "description": "Internal Server Error"
          }
        }
      }
    }
  },
  "components": {
    "schemas": {
      "ModeAnalysisResponse": {
        "type": "object",
        "properties": {
          "duration_seconds": {
            "type": "number",
            "format": "float",
            "description": "Total duration of the uploaded audio file in seconds."
          },
          "segment_seconds": {
            "type": "number",
            "format": "float",
            "description": "Duration of the analyzed audio segment in seconds."
          },
          "sample_rate": {
            "type": "integer",
            "description": "Sample rate of the audio in Hz."
          },
          "average_chroma": {
            "type": "array",
            "items": {
              "type": "number"
            },
            "minItems": 12,
            "maxItems": 12,
            "description": "A 12-element array representing the average activation of each pitch class (C, C#, ..., B) across the analyzed segment."
          },
          "chromagram_frames": {
            "type": "array",
            "items": {
              "type": "array",
              "items": {
                "type": "number"
              },
              "minItems": 12,
              "maxItems": 12
            },
            "description": "A list of 12-element arrays, where each inner array represents the pitch class activation for a single frame of the chromagram."
          },
          "frame_count_per_pitch_class": {
            "type": "object",
            "additionalProperties": {
              "type": "integer"
            },
            "description": "A dictionary mapping each pitch class (e.g., 'C', 'C#') to the number of frames where it had a strong activation."
          },
          "detected_notes": {
            "type": "array",
            "items": {
              "type": "string"
            },
            "description": "A list of pitch class names that were detected as significantly present in the audio segment."
          },
          "suggested_mode": {
            "type": "string",
            "description": "The musical mode (e.g., 'C Major', 'A Minor') that best matches the analyzed audio segment based on cosine similarity."
          },
          "local_key": {
            "type": "string",
            "description": "The tonic (root note) of the suggested musical mode (e.g., 'C', 'A')."
          },
          "match_scores": {
            "type": "object",
            "additionalProperties": {
              "type": "number"
            },
            "description": "A dictionary of similarity scores for various musical modes, indicating how well each mode matches the audio segment."
          },
          "visuals": {
            "type": "object",
            "properties": {
              "chromagram_base64": {
                "type": "string",
                "description": "Base64 encoded PNG image of the chromagram plot."
              },
              "histogram_base64": {
                "type": "string",
                "description": "Base64 encoded PNG image of the average pitch class activation histogram."
              }
            },
            "description": "Contains base64 encoded strings of generated visualizations."
          }
        },
        "required": [
          "duration_seconds",
          "segment_seconds",
          "sample_rate",
          "average_chroma",
          "chromagram_frames",
          "frame_count_per_pitch_class",
          "detected_notes",
          "suggested_mode",
          "local_key",
          "match_scores",
          "visuals"
        ]
      }
    }
  }
}